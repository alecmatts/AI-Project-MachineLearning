{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bittfconda3858df1c12d64690a67b7a8b0c2d6f56",
   "display_name": "Python 3.7.9 64-bit ('tf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLAB ONLY\n",
    "\n",
    "# Install Kaggle from PyPI\n",
    "!pip install -q kaggle\n",
    " \n",
    "# Kaggle: auth\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    " \n",
    "# Download dataset\n",
    "!kaggle datasets download -d crawford/emnist\n",
    " \n",
    "# Dataset: extract balanced only\n",
    "!unzip emnist.zip emnist-bymerge-test.csv\n",
    "!unzip emnist.zip emnist-bymerge-train.csv\n",
    "!unzip emnist.zip emnist-bymerge-mapping.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = pandas.read_csv('emnist-bymerge-train.csv')\n",
    "test_set = pandas.read_csv('emnist-bymerge-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.iloc[numpy.random.permutation(len(train_set))]\n",
    "test_set = test_set.iloc[numpy.random.permutation(len(test_set))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = numpy.array(train_set.iloc[:,0].values).reshape([train_set.shape[0], 1])\n",
    "train_data = numpy.array(train_set.iloc[:,1:].values).reshape([train_set.shape[0], 28, 28, 1])\n",
    "\n",
    "test_label = numpy.array(test_set.iloc[:,0].values).reshape([test_set.shape[0], 1])\n",
    "test_data = numpy.array(test_set.iloc[:,1:].values).reshape([test_set.shape[0], 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {\n",
    "    0: '0',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6', \n",
    "    7: '7',\n",
    "    8: '8', \n",
    "    9: '9',\n",
    "    10: 'A',\n",
    "    11: 'B',\n",
    "    12: 'C',\n",
    "    13: 'D',\n",
    "    14: 'E',\n",
    "    15: 'F',\n",
    "    16: 'G',\n",
    "    17: 'H',\n",
    "    18: 'I',\n",
    "    19: 'J',\n",
    "    20: 'K',\n",
    "    21: 'L',\n",
    "    22: 'M',\n",
    "    23: 'N',\n",
    "    24: 'O',\n",
    "    25: 'P',\n",
    "    26: 'Q',\n",
    "    27: 'R',\n",
    "    28: 'S',\n",
    "    29: 'T',\n",
    "    30: 'U',\n",
    "    31: 'V',\n",
    "    32: 'W',\n",
    "    33: 'X',\n",
    "    34: 'Y',\n",
    "    35: 'Z',\n",
    "    36: 'a',\n",
    "    37: 'b',\n",
    "    38: 'd',\n",
    "    39: 'e',\n",
    "    40: 'f',\n",
    "    41: 'g',\n",
    "    42: 'h',\n",
    "    43: 'n',\n",
    "    44: 'q',\n",
    "    45: 'r',\n",
    "    46: 't'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform label\n",
    "train_label = tf.keras.utils.to_categorical(train_label, 47)\n",
    "test_label = tf.keras.utils.to_categorical(test_label, 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype('float16')\n",
    "test_data = test_data.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data /= 255\n",
    "test_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 1\n",
    "model.add(tf.keras.layers.Conv2D(32,3, padding=\"same\", input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.LeakyReLU())\n",
    "model.add(tf.keras.layers.Conv2D(32,3, padding=\"same\"))\n",
    "model.add(tf.keras.layers.LeakyReLU())\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "# Block 2\n",
    "model.add(tf.keras.layers.Conv2D(64,3, padding  =\"same\"))\n",
    "model.add(tf.keras.layers.LeakyReLU())\n",
    "model.add(tf.keras.layers.Conv2D(64,3, padding  =\"same\"))\n",
    "model.add(tf.keras.layers.LeakyReLU())\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(47, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(train_data, train_label, epochs=3, batch_size=256, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.savefig('acc_basic_cnn.png')\n",
    "\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.savefig('loss_basic_cnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data, test_label)"
   ]
  },
  {
   "source": [
    "test_p = numpy.argmax(model.predict(test_data),axis=1)\n",
    "test_l = numpy.argmax(test_label,axis=1)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 5 # defining no. of rows in figure\n",
    "cols = 10 # defining no. of colums in figure\n",
    "\n",
    "f = plt.figure(figsize=(2 * cols, 2 * rows)) # defining a figure \n",
    "\n",
    "test_data *= 255\n",
    "test_data = test_data.astype('uint8')\n",
    "\n",
    "for i in range(rows * cols): \n",
    "    f.add_subplot(rows, cols, i+1) # adding sub plot to figure on each iteration\n",
    "    plt.imshow(test_data[i].reshape([28,28]),cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(str('P: ' + label[test_p[i]]) + str(' L: ' + label[test_l[i]]) , y=-0.2, color=\"green\")\n",
    "    plt.savefig('result_cnn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(test_l, test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting normalize=True.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, numpy.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = numpy.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "class_names = [str(i) for i in range(47)]\n",
    "numpy.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(50,20))\n",
    "plot_confusion_matrix(cm, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(50,20))\n",
    "plot_confusion_matrix(cm, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 5\n",
    "cols = 10\n",
    "count = 50\n",
    "\n",
    "f = plt.figure(figsize=(2*cols,2*rows))\n",
    "sub_plot = 1\n",
    "for i in range(test_data.shape[0]):\n",
    "    if test_l[i]!=test_p[i] and count != 0:\n",
    "        count -= 1\n",
    "        f.add_subplot(rows,cols,sub_plot) \n",
    "        sub_plot+=1\n",
    "        plt.imshow(test_data[i].reshape([28,28]),cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"T: \"+label[test_l[i]]+\" P: \"+label[test_p[i]], y=-0.2, color=\"Green\")\n",
    "plt.savefig(\"error_plots_cnn.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.keras.models.load_model(\"cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = loaded.evaluate(test_data, test_label)"
   ]
  }
 ]
}